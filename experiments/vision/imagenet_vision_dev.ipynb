{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchinfo\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger\n",
    "import torchmetrics\n",
    "\n",
    "import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys; sys.path.append('../..')\n",
    "from vision_models import ViT, VAT, configure_optimizers\n",
    "from utils.pl_tqdm_progbar import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4096\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from imagenet_data_utils import ImageNetKaggle\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean,std=std)\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "val_transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "\n",
    "def inv_normalize(tensor, mean=mean, std=std):\n",
    "    mean = torch.as_tensor(mean, dtype=tensor.dtype, device=tensor.device)\n",
    "    std = torch.as_tensor(std, dtype=tensor.dtype, device=tensor.device)\n",
    "    if mean.ndim == 1:\n",
    "        mean = mean.view(-1, 1, 1)\n",
    "    if std.ndim == 1:\n",
    "        std = std.view(-1, 1, 1)\n",
    "    tensor.mul_(std).add_(mean)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "root = '/home/ma2393/scratch/datasets/imagenet'\n",
    "train_ds = ImageNetKaggle(root, \"train\", train_transform)\n",
    "train_dataloader = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch_size, # may need to reduce this depending on your GPU \n",
    "            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "val_ds = ImageNetKaggle(root, \"val\", val_transform)\n",
    "val_dataloader = DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=batch_size, # may need to reduce this depending on your GPU \n",
    "            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "n_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for x, y in tqdm(dataloader):\n",
    "#         y_pred = model(x.cuda())\n",
    "#         correct += (y_pred.argmax(axis=1) == y.cuda()).sum().item()\n",
    "#         total += len(y)\n",
    "# print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = next(iter(train_dataloader))\n",
    "\n",
    "# n_samples = 5\n",
    "# fig, axs = plt.subplots(ncols=n_samples, figsize=(12, 4))\n",
    "# for s, ax in zip(np.random.choice(len(y), n_samples), axs):\n",
    "#     img = inv_normalize(x[s])\n",
    "#     ax.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "#     ax.set_title(y[s].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available:  True\n",
      "device count:  1\n",
      "current device name:  NVIDIA A100 80GB PCIe\n",
      "Memory Usage:\n",
      "\tAllocated: 0.0 GB\n",
      "\tReserved:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print('cuda available: ', torch.cuda.is_available())\n",
    "print('device count: ', torch.cuda.device_count())\n",
    "print('current device name: ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print('Memory Usage:')\n",
    "print('\\tAllocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "print('\\tReserved:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "# optimization hyperparams\n",
    "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
    "# max_iters = 5000\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0\n",
    "decay_lr = True # whether to decay the learning rate\n",
    "lr_decay_iters = 5000 # make equal to max_iters usually\n",
    "weight_decay = 1e-1\n",
    "min_lr = 1e-4 # learning_rate / 10 usually\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
    "# warmup_iters = 100\n",
    "gradient_accumulation_steps = 32 # 1 # accumulate gradients over this many steps. simulates larger batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pytorch Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_dataloader:\n",
    "#     # print(x)\n",
    "#     print(x[0].shape)\n",
    "#     print(x[1].shape)\n",
    "#     # print(len(x))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_on_step = True\n",
    "\n",
    "class LitVisionModel(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = torch.nn.functional.cross_entropy\n",
    "        self.accuracy = lambda pred, y: torchmetrics.functional.accuracy(pred, y, task=\"multiclass\", num_classes=n_classes, top_k=1, average='micro')\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = self.accuracy(logits, y)\n",
    "\n",
    "        self.log('train/loss', loss, prog_bar=True, logger=True, on_step=log_on_step, on_epoch=True)\n",
    "        self.log('train/acc', acc, prog_bar=True, logger=True, on_step=log_on_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = self.accuracy(logits, y)\n",
    "\n",
    "        self.log(f\"val/loss\", loss, prog_bar=True, logger=True, add_dataloader_idx=False)\n",
    "        self.log(f\"val/acc\", acc, prog_bar=True, logger=True, add_dataloader_idx=False)\n",
    "\n",
    "        for k in range(1, topks):\n",
    "            acc = torchmetrics.functional.accuracy(logits, y, task=\"multiclass\", num_classes=n_classes, top_k=k, average='micro')\n",
    "            self.log(f\"val/top{k}_acc\", acc, prog_bar=True, logger=True, add_dataloader_idx=False)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = configure_optimizers(self.model, weight_decay, learning_rate, (beta1, beta2), device_type=device)\n",
    "        return optimizer\n",
    "\n",
    "# endregion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c, w, h = images.shape[1:]\n",
    "c, w, h = (3, 224, 224)\n",
    "image_shape = (c, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model args\n",
    "symbol_type = 'pos_relative'\n",
    "d_model, n_layers, dff = 768, 12, None\n",
    "sa, rca = 12, 0\n",
    "patch_size = (16, 16)\n",
    "n_patches = (w // patch_size[0]) * (h // patch_size[1])\n",
    "activation = 'swiglu'\n",
    "dropout_rate = 0.1\n",
    "rca_type = 'disentangled_v2'\n",
    "norm_first = True\n",
    "bias = False\n",
    "pool = 'cls'\n",
    "\n",
    "run_name = f'sa={sa}; rca={rca}; d={d_model}; L={n_layers}; rca_type={rca_type}; symbol_type={symbol_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %\n",
      "============================================================================================================================================\n",
      "ViT                                      [1, 3, 224, 224]          [1, 1000]                 152,064                     0.13%\n",
      "├─Sequential: 1-1                        [1, 3, 224, 224]          [1, 196, 768]             --                             --\n",
      "│    └─Rearrange: 2-1                    [1, 3, 224, 224]          [1, 196, 768]             --                             --\n",
      "│    └─LayerNorm: 2-2                    [1, 196, 768]             [1, 196, 768]             1,536                       0.00%\n",
      "│    └─Linear: 2-3                       [1, 196, 768]             [1, 196, 768]             590,592                     0.51%\n",
      "│    └─LayerNorm: 2-4                    [1, 196, 768]             [1, 196, 768]             1,536                       0.00%\n",
      "├─Dropout: 1-2                           [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "├─ModuleList: 1-3                        --                        --                        --                             --\n",
      "│    └─EncoderBlock: 2-5                 [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-1                 [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-2               --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-3                 [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-4                 [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-5        [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-6                 [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-6                 [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-7                 [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-8               --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-9                 [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-10                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-11       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-12                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-7                 [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-13                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-14              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-15                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-16                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-17       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-18                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-8                 [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-19                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-20              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-21                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-22                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-23       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-24                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-9                 [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-25                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-26              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-27                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-28                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-29       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-30                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-10                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-31                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-32              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-33                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-34                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-35       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-36                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-11                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-37                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-38              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-39                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-40                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-41       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-42                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-12                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-43                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-44              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-45                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-46                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-47       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-48                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-13                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-49                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-50              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-51                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-52                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-53       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-54                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-14                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-55                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-56              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-57                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-58                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-59       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-60                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-15                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-61                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-62              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-63                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-64                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-65       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-66                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "│    └─EncoderBlock: 2-16                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-67                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─Attention: 3-68              --                        [1, 197, 768]             2,360,064                   2.05%\n",
      "│    │    └─Dropout: 3-69                [1, 197, 768]             [1, 197, 768]             --                             --\n",
      "│    │    └─RMSNorm: 3-70                [1, 197, 768]             [1, 197, 768]             768                         0.00%\n",
      "│    │    └─FeedForwardBlock: 3-71       [1, 197, 768]             [1, 197, 768]             7,084,800                   6.17%\n",
      "│    │    └─Dropout: 3-72                [1, 197, 768]             [1, 197, 768]             --                        (recursive)\n",
      "├─Linear: 1-4                            [1, 768]                  [1, 1000]                 769,000                     0.67%\n",
      "============================================================================================================================================\n",
      "Total params: 114,871,528\n",
      "Trainable params: 114,871,528\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 114.72\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 221.49\n",
      "Params size (MB): 458.88\n",
      "Estimated Total Size (MB): 680.97\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# define kwargs for symbol-retrieval module based on type\n",
    "rca_kwargs = dict()\n",
    "if symbol_type == 'sym_attn':\n",
    "    symbol_retrieval_kwargs = dict(d_model=d_model, n_symbols=50, n_heads=4) # NOTE: n_heads, n_symbols fixed for now\n",
    "elif symbol_type == 'pos_sym_retriever':\n",
    "    symbol_retrieval_kwargs = dict(symbol_dim=d_model, max_length=n_patches+1)\n",
    "elif symbol_type == 'pos_relative':\n",
    "    symbol_retrieval_kwargs = dict(symbol_dim=d_model, max_rel_pos=n_patches+1)\n",
    "    rca_kwargs['use_relative_positional_symbols'] = True # if using position-relative symbols, need to tell RCA module\n",
    "elif rca != 0:\n",
    "    raise ValueError(f'`symbol_type` {symbol_type} not valid')\n",
    "\n",
    "# if rca=0, use TransformerLM\n",
    "if rca == 0:\n",
    "    model_args = dict(\n",
    "        image_shape=image_shape, patch_size=patch_size, num_classes=n_classes, pool=pool,\n",
    "        d_model=d_model, n_layers=n_layers, n_heads=sa, dff=dff, dropout_rate=dropout_rate,\n",
    "        activation=activation, norm_first=norm_first, bias=bias)\n",
    "\n",
    "    model = transformer_lm = ViT(**model_args).to(device)\n",
    "# otherwise, use AbstractTransformerLM\n",
    "else:\n",
    "    model_args = dict(\n",
    "        image_shape=image_shape, patch_size=patch_size, num_classes=n_classes, pool=pool,\n",
    "        d_model=d_model, n_layers=n_layers, n_heads_sa=sa, n_heads_rca=rca, dff=dff, dropout_rate=dropout_rate,\n",
    "        activation=activation, norm_first=norm_first, bias=bias, rca_type=rca_type,\n",
    "        symbol_retrieval=symbol_type, symbol_retrieval_kwargs=symbol_retrieval_kwargs, rca_kwargs=rca_kwargs)\n",
    "\n",
    "    model = abstracttransformer_lm = VAT(**model_args).to(device)\n",
    "\n",
    "print(torchinfo.summary(\n",
    "    model, input_size=(1, *image_shape),\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\", \"params_percent\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unoptimized_model = model\n",
    "# model = torch.compile(model)\n",
    "lit_model = LitVisionModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_to_wandb = False\n",
    "n_epochs = 1\n",
    "max_steps = -1\n",
    "log_every_n_steps = 20\n",
    "eval_interval = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lit_model = torch.compile(lit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma2393/.conda/envs/abstract_transformer/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/ma2393/.conda/envs/abstract_transformer/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-05-03 16:17:31.537963: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-03 16:17:32.962592: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-03 16:17:32.962643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-03 16:17:33.086766: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-03 16:17:33.133379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 16:17:38.436784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | ViT  | 114 M \n",
      "-------------------------------\n",
      "114 M     Trainable params\n",
      "0         Non-trainable params\n",
      "114 M     Total params\n",
      "459.486   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 88, with 114,756,096 parameters\n",
      "num non-decayed parameter tensors: 78, with 115,432 parameters\n",
      "using fused AdamW: True\n",
      "Epoch 0:   1%|          | 124/20018 [00:26<1:09:39,  4.76it/s, v_num=5807, train/loss_step=10.70, train/acc_step=0.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma2393/.conda/envs/abstract_transformer/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "if log_to_wandb:\n",
    "    run = wandb.init(project=wandb_project, group=group_name, name=run_name,\n",
    "        config={'group': group_name, 'num_params': num_params, **model_args})\n",
    "\n",
    "    wandb_logger = WandbLogger(experiment=run, log_model=log_model),\n",
    "else:\n",
    "    wandb_logger = None\n",
    "\n",
    "callbacks = [\n",
    "    # TQDMProgressBar(refresh_rate=50)\n",
    "    TQDMProgressBar(),\n",
    "    L.pytorch.callbacks.ModelCheckpoint(dirpath=f'out/{run_name}', every_n_train_steps=10) #every_n_epochs=1)\n",
    "]\n",
    "\n",
    "trainer_kwargs = dict(\n",
    "    max_epochs=n_epochs, enable_model_summary=True, benchmark=True, enable_checkpointing=True,\n",
    "    enable_progress_bar=True, callbacks=callbacks, logger=wandb_logger,\n",
    "    accumulate_grad_batches=gradient_accumulation_steps, gradient_clip_val=grad_clip,\n",
    "    # log_every_n_steps=log_every_n_steps, max_steps=max_steps, val_check_interval=eval_interval) # FIXME\n",
    "    log_every_n_steps=log_every_n_steps, max_steps=100)#, val_check_interval=eval_interval)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    **trainer_kwargs\n",
    "    )\n",
    "\n",
    "trainer.fit(model=lit_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "# endregion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 21:40:35.062466: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-02 21:40:36.188600: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 21:40:36.188649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 21:40:36.214019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-02 21:40:36.228311: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 21:40:40.441201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 781/781 [03:36<00:00,  3.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0010003200732171535   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val/loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     7.431337833404541     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top1_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0010003200732171535   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top2_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0024607875384390354   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top3_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.003481114050373435    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top4_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.004061299841850996    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top5_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.005081626120954752    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top6_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0059619080275297165   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top7_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.006862195674329996    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top8_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.007822503335773945    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/top9_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.008722791448235512    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010003200732171535  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.431337833404541    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top1_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010003200732171535  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top2_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0024607875384390354  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top3_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.003481114050373435   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top4_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.004061299841850996   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top5_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.005081626120954752   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top6_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0059619080275297165  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top7_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.006862195674329996   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top8_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.007822503335773945   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val/top9_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.008722791448235512   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val/loss': 7.431337833404541,\n",
       "  'val/acc': 0.0010003200732171535,\n",
       "  'val/top1_acc': 0.0010003200732171535,\n",
       "  'val/top2_acc': 0.0024607875384390354,\n",
       "  'val/top3_acc': 0.003481114050373435,\n",
       "  'val/top4_acc': 0.004061299841850996,\n",
       "  'val/top5_acc': 0.005081626120954752,\n",
       "  'val/top6_acc': 0.0059619080275297165,\n",
       "  'val/top7_acc': 0.006862195674329996,\n",
       "  'val/top8_acc': 0.007822503335773945,\n",
       "  'val/top9_acc': 0.008722791448235512}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(lit_model, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abstract_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
