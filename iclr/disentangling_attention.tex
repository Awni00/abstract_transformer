\section{Disentangling Attention over Sensory and Relational Information}

\subsection{Standard Attention: Attention over Sensory Information}

\aanote{need to specify $x,y$ are vectors, say of dimension $d$?}

The attention mechanism of standard Transformers can be understood as a form of neural message-passing that performs selective information retrieval over the sensory information in the context. An object emits a query that is compared against the keys of each object in its context via an inner product. A match occurs when the inner product is large, causing an encoding of the features of the attended object to be retrieved and added to the residual stream of the receiver. Formally, attention between an object $x \in \reals^d$ and a context $\y = \ys \in \reals^{n \times d}$ takes the form
\begin{equation}\label{eq:self_attn}
  \begin{split}
    \Attn(x, \ys) &= \sum_{i=1}^{n} \alpha_i(x, \y) \phi_v(y_i), \ \text{where}, \\
    \alpha(x, \y) &= \Softmax\bigparen{\bra{\iprod{\phiqattn(x)}{\phikattn(y_i)}}_{i=1}^{n}},
  \end{split}
\end{equation}
where $\phiqattn,\phikattn$ are learnable query and key maps controlling the selection criterion, and $\phi_v$ is a learnable value map controlling what information about $y_i$ is sent. The attention scores $\alpha(x, \y) \in \Delta^n$ are used to retrieve a convex combination of the values, where $\alpha_i(x, \y)$ denotes the $i$-th component.

Here, the retrieved information is \textit{sensory}, comprising the features and attributes of individual objects in the context. For this reason, we refer to standard neural attention as ``sensory attention''.

% The attention scores $\alpha_i(x, \y)$ can perhaps be thought of as (normalized) relations between objects, but these are merely computed as an intermediate step in an information-retrieval operation, and are ultimately entangled with the object-level sensory features of the sender\footnote{In principle, it is also possible that the MLP compute a relation between the sender and receiver in the local processing step by separating their representations and computing a comparison. However, this is difficult to do since the representations of the objects will be additively mixed, and there is no inductive bias pressuring the computed function to be a relation.}. 

\subsection{Relational Attention: Attention over Relational Information}

Standard neural attention does not explicitly capture information about the \textit{relationship} between the sender and the receiver, making relational learning in standard Transformers inefficient~\citep{lake2018generalization,barrett2018measuring,santoroSimpleNeuralNetwork2017,santoroRelationalRecurrentNeural2018,shanahanExplicitlyRelationalNeurala,webbEmergentSymbolsBinding2021,webbRelationalBottleneckInductive2024,kergNeuralArchitectureInductive2022,altabaa2024abstractors,altabaaLearningHierarchicalRelational2024}. We propose \textit{relational attention}, a novel attention mechanism for dynamically routing relational information between objects. Under the message-passing view of \cref{eq:intro_message_passing}, relational attention represents an operation where the message from one object to another encodes the relationship between them.

Mirroring standard attention, this operation begins with each object emitting a query and a key, which are compared via an inner product to compute attention scores determining which objects to attend to. Next, instead of retrieving the sensory features of the selected object, relational attention retrieves the \textit{relation} between the two objects---defined as a series of comparisons between the two objects under different feature subspaces. In addition, a symbolic identifier is sent to indicate the identity of the sender to the receiver. Mathematically, this operation is defined as follows.
\begin{equation}\label{eq:rel_attn}
  \begin{split}
    \RelAttn(x, \ys) &= \sum_{i=1}^{n} \alpha_i(x, \y) \bigparen{r(x, y_i) W_r + s_i W_s}, \ \text{where},\\
    \alpha(x, \y) &= \Softmax\bigparen{\bra{\iprod{\phiqattn(x)}{\phikattn(y_i)}}_{i=1}^{n}}, \\
    % r(x, y_i) &= \bigparen{\iprod{\phi_{q,1}^{\rel}(x)}{\phi_{k,1}^{\rel}(y_i)}, \ldots, \iprod{\phi_{q, d_r}^{\rel}(x)}{\phi_{k, d_r}^{\rel}(y_i)}}, \\
    r(x, y_i) &= \bigparen{\iprod{\phiqrell{\ell}(x)}{\phikrell{\ell}(y_i)}}_{\ell \in [d_r]}, \\
    % r(x, y_i) &= \bigbra{\iprod{\phiqrell{\ell}(x)}{\phikrell{\ell}(y_i)}}_{\ell = 1}^{d_r}, \\
    (s_1, \ldots, s_n) &= \SymbolRetriever(\y;\,\Slib)
  \end{split}
\end{equation}

\aanote{if there's space, add footnote to explain $x = {(x_i)}_{i \in \calI}$ and ${[a_i]}_{i=1}^{n}$ notation.}

Thus, relational attention between the object $x$ and the context $\y = \ys$ retrieves a convex combination of the relation vectors $\{r(x, y_i)\}_{i=1}^{n}$, representing $x$'s relationship with each object in the context. The relations are annotated with a symbol vector $s_i$, selected from a learned symbol library $\Slib$, that encodes the identity information of the corresponding object. The role and implementation of the symbols will be discussed in the next subsection. As with standard attention, $\phiqattn, \phikattn$ are learned feature maps that govern which object(s) in the context to attend to. Another set of query and key feature maps, $\phiqrell{\ell}, \phikrell{\ell}, \ell \in [d_r]$, are learned to represent the relation between the sender and the receiver. For each $\ell \in [d_r]$, the feature maps $\phiqrell{\ell}, \phikrell{\ell}$ extract specific attributes from the object pair, which are compared by an inner product. This produces a $d_r$-dimensional relation vector representing a fine-grained series of comparisons $\pparen{\iiprod{\phiqrell{\ell}(x)}{\phikrell{\ell}(y_i)}}_{\ell \in [d_r]}$ across different feature subspaces.

In certain tasks~\citep{kergNeuralArchitectureInductive2022,altabaa2024abstractors,altabaaLearningHierarchicalRelational2024}, a useful inductive bias on the relations function $r(\cdot, \cdot)$ is symmetry; i.e., $r(x, y) = r(y, x),\, \forall x, y$. This corresponds to using the same feature filter for the query and key maps, $\phiqrel = \phikrel$. This adds structure to the relation function, transforming it into a positive semi-definite kernel that defines a pseudometric on the object space, along with a corresponding geometry. %We explore this and expand on this discussion in our experiments.

\subsection{Symbol Assignment Mechanisms}

% For the purposes of processing relations, all the receiver needs to know is: 1) the relation between itself and the objects in its context, and 2) the identity of the object corresponding to each relation.
To process relational information effectively, the receiver must have two pieces of information: 1) its relationship to the objects in its context, and 2) the identity of the object associated with each relation. In relational attention, the former is captured by $r(x, y_i)$ and the latter by $s_i$.
The symbols $s_i$ are used to tag each relation with the identity information of the sender. %  (i.e., the object the relation involves).
% Without this identity information, the result of relational attention would only be an aggregated representation of the relations between the receiver and the context.
% NOTE: add above sentence back? is it important/clarifying?

The symbol $s_i$ identifies or points to the object $y_i$, but, importantly, is designed to not fully encode the features of the object.
Instead, the symbols $s_i$ function as abstract references to objects, perhaps viewed as a connectionist analog of pointers in traditional symbolic systems.
In particular, by drawing symbol vectors from a finite library $\Slib$ to identify objects, relational attention maintains a relation-centric representation.
This separation between sensory and relational information is key to making relational attention disentangled from sensory features, enabling generalization across relations.
% While sensory information tends to be high-dimensional, relational information is low-dimensional and more abstract. \edit{If sensory features are mixed with relational information, they may overwhelm the relational information, preventing abstraction and generalization.}

The notion of the ``identity'' of an object can vary depending on context. In this work, we consider modeling three types of identifiers: 1) position, 2) relative position, or 3) an equivalence class over features. For each type of identifier, we model a corresponding symbol assignment mechanism~\citep{altabaa2024abstractors}.

\textbf{Positional Symbols.} In some applications, it is sufficient to identify objects through their position in the input sequence. We maintain a library of symbols $\Slib = (s_1, \ldots, s_{\mathtt{max\_len}}) \in \reals^{\mathtt{max\_len} \times d}$ and assign $s_i$ to the $i$-th object in the sequence. These are essentially learned positional embeddings.

\textbf{Position-Relative Symbols.} Often, the \textit{relative} position with respect to the receiver is a more useful identifier than absolute position. This can be implemented with position-relative embeddings. We learn a symbol library $\Slib = (s_{-\Delta}, \ldots, s_{-1}, s_0, s_1, \ldots, s_{\Delta}) \in \reals^{(2 \Delta + 1) \times d}$, and relational attention becomes $\sum_{j} \alpha_{ij}  (r(x_i, x_j) \, W_r + s_{j-i} \,  W_s)$.%, with ``$m_{j \to i} = (r(x_i, x_j), s_{j-i})$''.

\textbf{Symbolic Attention.} In certain domains, some information about the objects' features is necessary for identifying them for the purposes of relational processing. Yet, to maintain a relational inductive bias, we would like to avoid sending a full encoding of object-level features. In symbolic attention, we learn a set of symbol vectors, $\Slib = (s_1, \ldots, s_{n_s}) \in \reals^{n_s \times d}$ and a matching set of feature templates $\Flib = (f_1, \ldots, f_{n_s})$. We retrieve a symbol for each object by an attention operation that matches the input vectors $x_i$ against the feature templates $f_j$ and retrieves symbols $s_j$.
\begin{equation}
  \SymbolicAttn(\x) = \Softmax\bigparen{(\x \, W_q)\, \Flib^\top} \Slib.
\end{equation}
Here, $\Slib, \Flib, W_q$ are learned parameters. This can be thought of as implementing a learned differentiable ``equivalence class map'' over feature embeddings. Crucially, the number of symbols (i.e., feature equivalence classes) is \textit{finite}, which enables relational attention to still produce a relation-centric representation while tagging the relations with the necessary identifier.

We find that different symbol assignment mechanisms are more effective in different domains.

\aawarning{add further discussion on symbol assignment mechanisms here (or somewhere else?); maybe add appendix section.}

% \subsection{Approximation theory: What Class of Functions can Relational Attention Compute?}\label{ssec:approx}
\subsection{What Class of Functions can Relational Attention Compute?}\label{ssec:approx}
\aanote{update $\calX, \calY$ to $\reals^d$?}
To get some intuition about the type of computation that relational attention can perform, we present the following approximation result. The following theorem states that relational attention can approximate any function on $\calX \times \calY^n$ that 1) selects an element in $\ys$, then 2) computes a relation with it. Both the selection criterion and the relation function are arbitrary, and the selection criterion is query-dependent. The formal statement and proof are given in~\Cref{sec:approx}.
\begin{theorem}[Informal]\label{theorem:func_class}
  Let $\mathrm{Select}: \calX \times \calY^n \to \calY$ be an arbitrary preference selection function, which selects an element among $\ys$ based on a query-dependent preorder relation $\{\preceq_x\}_{x \in \calX}$. Let $\mathrm{Rel}: \calX \times \calY \to \reals^{d_r}$ be an arbitrary continuous relation function on $\calX \times \calY$. There exists a relational attention module that approximates the function $\mathrm{Rel}(x, \mathrm{Select}(x, \y))$ to arbitrary precision.
\end{theorem}
