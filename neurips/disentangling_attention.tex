\section{Disentangling Attention over Sensory and Relational Information}

\subsection{Standard Attention: Attention over Sensory Information}

The attention mechanism of standard Transformers can be understood as a form of neural message-passing that performs selective information retrieval. An object emits a query that is compared against the keys of each object in its context via an inner product. A ``match'' occurs when the inner product is large, causing the features of the attended object to be retrieved and added to the residual stream of the receiver. Formally, standard attention takes the form
\begin{equation}\label{eq:self_attn}
  \begin{split}
    \Attn(x, \ys) &= \sum_{i=1}^{n} \alpha_i(x, \y) \phi_v(y_i) \\
    \alpha(x, \y) &= \Softmax\bigparen{\bra{\iprod{\phi_q(x)}{\phi_k(y_i)}}_{i=1}^{n}},
  \end{split}
\end{equation}
where $\phi_q,\phi_k$ are learnable query/key maps controlling the selection criterion and $\phi_v$ is a learnable value mapping controlling what information is sent. The attention scores $\alpha(x, \y) \in \Delta^n$ are used to retrieve a convex combination of the values.

The information being retrieved here is ``sensory'' information---that is, the features and attributes of individual objects. There is no explicit retrieval of information about the \textit{relationship} between the features of the sender and the receiver. The attention scores $\alpha_i(x, \y)$ can perhaps be thought of as (normalized) relations between objects, but these are merely computed as an intermediate step in an information-retrieval operation, and are ultimately entangled with the object-level features of the sender\footnote{In principle, it is also possible that the MLP compute a relation between the sender and receiver in the local processing step by separating out their representations and computing a comparison. However, this is difficult to do since the representations of the objects will be additively mixed, and there is no inductive bias pressuring the computed function to be a relation.}. This makes learning relational representations in standard Transformers inefficient.

\subsection{Relational Attention: Attention over Relational Information}

We propose a type of ``attention head'' with a relational inductive bias. Under the message-passing view of \Cref{eq:intro_message_passing}, the message sent from one object to another encodes the relation between the sender and the receiver. We call this operation \textit{relational attention}.

At a high-level, this operation begins in the same way as the standard attention mechanism, with each object emitting a query and a key, which are compared via an inner product. When the inner product is high, an object is selected. But, now rather than retrieving the features of the selected object, what is retrieved is the \textit{relation} between the two objects. In addition, we must send an identifier that signifies to the receiver ``who the relation is with.'' Mathematically, this operation is defined as follows.
\begin{equation}\label{eq:rel_attn}
  \begin{split}
    \RelAttn(x, \ys) &= \sum_{i=1}^{n} \alpha_i(x, \y) \bigparen{W_r \, r(x, y_i) + W_s \, s_i}, \\
    \alpha(x, \y) &= \Softmax\bigparen{\bra{\iprod{\phiqattn(x)}{\phikattn(y_i)}}_{i=1}^{n}}, \\
    r(x, y) &= \bigparen{\iprod{\phi_{q,1}^{\rel}(x)}{\phi_{k,1}^{\rel}(y)}, \ldots, \iprod{\phi_{q, d_r}^{\rel}(x)}{\phi_{k, d_r}^{\rel}(y)}} \in \reals^{d_r}, \\
    (s_1, \ldots, s_n) &= \SymbolRetriever(\y;\,\Slib)
  \end{split}
\end{equation}

Thus, relational attention between the object $x$ and the context $\y = \ys$ retrieves a convex combination of $x$'s relations $r(x, y_i)$ with each object $y_i$ in the context, with each relation tagged with a symbol $s_i$ that identifies the sender. We will expand on the role and implementation of the symbols in the next subsection. Here, $\phiqattn, \phikattn$ are learned feature maps controlling the selection criterion of which object(s) in the context to attend to. Another set of query/key feature maps, $\phi_{q,i}^{\rel}, \phi_{k,i}^{\rel}, i \in [d_r]$, are learned to represent the relation between the sender and the relation. Each inner product $\iprod{\phiqrel(x)}{\phikrel(y)}$ can be thought of as a comparison of the two objects' features under a particular filter---a `relation'. The $d_r$ (pairs) of feature maps produce a $d_r$-dimensional relation vector.

In some tasks, a good inductive bias on the relations is \textit{symmetry}: the relation between $x$ and $y$ is the same as the relation between $y$ and $x$. This can be achieved by using the same feature filter for the query and key map (i.e., $\phiqrel = \phikrel$). This imbues the relations with added structure, making them positive semi-definite kernels which define a pseudometric on the object space and a corresponding geometry. We explore symmetry and expand on this discussion in our experiments.

\subsection{Symbol Assignment Mechanisms}

%For the purposes of processing relations, all the receiver needs to know is: 1) the relation between itself and the objects in its context, and 2) the identity of the object corresponding to each relation. 
%\aanote*{this sentence (and paragraph?) are a bit complicated and unclear. maybe revise. e.g., ``the retrieved relation is tagged with a symbol identifying the sender.''... another possibility: ``the role of the symbols $(s_1, \ldots, s_n)$ is to encode the identity of each object so that the message from the sender $y_i$ to the receiver $x$ attaches the identity of the sender $s_i$ to the relation $r(x, y_i)$. The ``identity'' of the sender can encode their position in the sequence, their relative position with respect to the receiver, or their syntactic role.''}{
The symbols in relational attention are used to tag each relation with the identity of the object the 
relation is with. Without this information, the result of relational attention would only be an aggregated representation of the relations between the receiver and the selected object(s).

While a symbol identifies or points to an object, it crucially does not fully encode the features of the object. This is what makes relational attention (\Cref{eq:rel_attn}) ``disentangled'' from sensory or object-level features. The sensory features of individual objects are high-dimensional and have great variability. In contrast, relational information is low-dimensional and more abstract. If sensory object-level features are mixed with relational information, the sensory information could overwhelm the relational information, preventing abstraction and generalization. Instead, symbols act as abstract references to objects, and maybe be thought of as connectionist analogues of pointers in traditional symbolic architectures.

Here, the ``identity'' of an object may mean different things in different situations. For us, identity may be encoded by 1) position, 2) relative position, or 3) an equivalence class over features. 
Correspondingly, we consider three different symbol assignment mechanisms.

\textbf{Positional Symbols.} In some applications, it is sufficient to identify objects through their position in the input sequence. We maintain a library of symbols $\Slib = (s_1, \ldots, s_{\mathtt{max\_len}}) \in \reals^{\mathtt{max\_len} \times d_{\mathrm{model}}}$ and assign $s_i$ to the $i$-th object in the sequence. These are essentially learned positional embeddings.

\textbf{Position-Relative Symbols.} Sometimes, the more relevant identifier is \textit{relative} position with respect to the receiver, rather than absolute position. This can be implemented with position-relative embeddings. We learn a symbol library $\Slib = (s_{-\Delta}, \ldots, s_{-1}, s_0, s_1, \ldots, s_{\Delta}) \in \reals^{(2 \Delta + 1) \times d_{\mathrm{model}}}$, and relational attention becomes $x_i' \gets \sum_{j} \alpha_{ij} (W_r \, r(x_i, x_j) + W_s \, (s_{j-i}))$, with ``$m_{j \to i} = (r(x_i, x_j), s_{j-i})$.

\textbf{Symbolic Attention.} In certain domains, some information about the objects' features is necessary for identifying it for the purposes of relational processing. Yet, recall that we would like to avoid sending a full encoding of object-level features in order to maintain a relational inductive bias and the ability for \aanote*{or ``generalization''}{abstraction} across relations. In symbolic attention, we learn a small set of symbol vectors, $\Slib = (s_1, \ldots, s_{n_s}) \in \reals^{n_s \times d_{\mathrm{model}}}$, and a matching set of feature templates $\Flib = (f_1, \ldots, f_{n_s})$. We retrieve a symbol for each object by an attention operation that matches the input vectors 
$x_i$ against the feature templates $f_j$, and retrieves symbols $s_j$.
\begin{equation}
  \SymbolicAttn(\x) = \Softmax\bigparen{(\x \, W_q)\, \Flib^\top} \Slib.
\end{equation}
Here, $\Slib, \Flib, W_q$ are learned parameters. This can be thought of as implementing a learned differentiable ``equivalence class map'' over feature embeddings. Crucially, the number of symbols (i.e., ``feature equivalence classes'') is limited, which enables relational attention to still produce a relation-centric representation while tagging the relations with the necessary identifier. Our implementation allows for a multi-head variant of this operation.

In our experiments, we find that different symbol assignment mechanisms are more effective in different domains.

%\aanote{do we need to cite ourselves here?} I don't think so

\aanote{Symbols as ``codes'' that identify objects without encoding their features.}

\subsection{Approximation theory: What Class of Functions can Relational Attention Compute?}

The following theorem says that an relational attention can approximate any function on $\calX \times \calY^n$ which 1) selects an element in $\ys$, then 2) computes a relation with it. Both the selection criterion and the relation function are arbitrary, and the selection criterion is query-dependent.
\begin{theorem}[Informal]
  Let $\mathrm{Select}: \calX \times \calY^n \to \calY$ be an arbitrary preference selection function, which selects an element among $\ys$ based on a query-dependent preorder relation $\{\preceq_x\}_{x \in \calX}$. Let $r: \calX \times \calY \to \reals^{d_r}$ be an arbitrary continuous relation function on $\calX \times \calY$. For any such $\mathrm{Select}$ and $r$, there exists a relational attention module which approximates the function $r(x, \mathrm{Select}(x, \y))$ to arbitrary precision.
\end{theorem}