\begin{abstract}
  The Transformer architecture processes sequences by implementing a form of neural message-passing that consists of iterative information retrieval (attention), followed by local processing (position-wise MLP).
  We argue that for such a procedure, two types of contextual information are crucial: 1) object-level features of attended objects, and 2) the \textit{relations} between these objects and the receiver.
  Standard attention naturally captures the former, but does not explicitly support the latter.
  In this paper, we present an extension of Transformers where multi-head attention now consists of two distinct types of ``attention heads,'' each handling routing information of a different type. The first is the standard attention mechanism of Transformers which captures object-level features, while the second is a novel attention mechanism we propose that captures relational features.
  The two types of attention heads each possess different inductive biases, giving the resulting architecture greater efficiency and versatility.
  Empirical evaluation across a range of tasks, including visual relational reasoning, mathematical problem solving, and language modeling, demonstrates the promise of this approach.
\end{abstract}